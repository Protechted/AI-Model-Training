{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fall Detection RNN Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "from utils import load_data\n",
    "\n",
    "# random seed\n",
    "from random import randint\n",
    "\n",
    "# Tensorflow and Keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GRU, LSTM, Dropout, GaussianNoise, Input, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "# Optimization (Optuna)\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# metrics / evaluation\n",
    "from sklearn.metrics import f1_score\n",
    "from numpy import rint\n",
    "from numpy import load\n",
    "from numpy import concatenate\n",
    "\n",
    "# logging\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "# datetime\n",
    "import datetime\n",
    "\n",
    "# timestamp for wandb\n",
    "TIME = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples fetched\n",
      "Data fetched\n",
      "all_samples shape: (165, 200, 7)\n",
      "all_labels shape: (165,)\n",
      "X_train shape: (115, 200, 7)\n",
      "X_val shape: (25, 200, 7)\n",
      "X_test shape: (25, 200, 7)\n",
      "X_train shape: (1204, 150, 7), 1/0 ratio: 0.5963455149501661\n",
      "X_val shape: (254, 150, 7), 1/0 ratio: 0.5748031496062992\n",
      "X_test shape: (280, 150, 7), 1/0 ratio: 0.6357142857142857\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(OPTIONAL) load umafall data to augment th model training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_umafall = load(\"umafall/X_umafall.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_umafall = [1] * len(X_umafall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = concatenate([X_train, X_umafall])\n",
    "y_train = concatenate([y_train, y_umafall])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(trial, input_shape: tuple):\n",
    "\n",
    "    dropout = trial.suggest_categorical(\"dropout\", [0.0, 0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "    #recurrent_dropout = trial.suggest_categorical(\"recurrent_dropout\", [0.0, 0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "    gaussian_noise = trial.suggest_float(\"gaussian_noise\", 0.0, 0.2)\n",
    "    #bidirectional = trial.suggest_categorical(\"bidirectional\", [True, False])\n",
    "    rnn_variant = trial.suggest_categorical(\"rnn_variant\", [\"gru\", \"lstm\"])\n",
    "    units = trial.suggest_categorical(\"n_units\", [16, 32, 64, 128])\n",
    "    activation = trial.suggest_categorical(\"activation\", [\"relu\", \"tanh\", \"leaky_relu\"])\n",
    "\n",
    "    config = {\n",
    "        \"dropout\": dropout,\n",
    "        #\"recurrent_dropout\": recurrent_dropout,\n",
    "        \"gaussian_noise\": gaussian_noise,\n",
    "        #\"bidirectional\": bidirectional,\n",
    "        \"rnn_variant\": rnn_variant,\n",
    "        \"n_units\": units,\n",
    "        \"activation\": activation,\n",
    "    }\n",
    "\n",
    "    input = Input(shape=input_shape)\n",
    "    o = GaussianNoise(gaussian_noise)(input)\n",
    "\n",
    "    if rnn_variant == \"gru\":\n",
    "        #if bidirectional:\n",
    "        #    gru = GRU(units, return_sequences=False, activation=activation, recurrent_dropout=recurrent_dropout, dropout=dropout)\n",
    "        #    o = Bidirectional(gru)(o)\n",
    "        #else:\n",
    "        o = GRU(units, return_sequences=True)(o)\n",
    "        o = GRU(units, return_sequences=False)(o)\n",
    "\n",
    "    elif rnn_variant == \"lstm\":\n",
    "        #if bidirectional:\n",
    "        #    lstm = LSTM(units, return_sequences=False, activation=activation, recurrent_dropout=recurrent_dropout, dropout=dropout)\n",
    "        #    o = Bidirectional(lstm)(o)\n",
    "        #else:\n",
    "        o = LSTM(units, return_sequences=True)(o)\n",
    "        o = LSTM(units, return_sequences=False)(o)\n",
    "\n",
    "    o = Dense(units, activation=activation)(o)\n",
    "    o = Dropout(dropout)(o)\n",
    "    o = Dense(1, activation=\"sigmoid\")(o)\n",
    "\n",
    "    model = Model(inputs=input, outputs=o)\n",
    "    return model, config\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.001, 0.05)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128, 256])\n",
    "    optimizer = trial.suggest_categorical(\"optimizer\", [\"adam\", \"sgd\", \"rmsprop\"])\n",
    "\n",
    "    model, config = get_model(trial, (X_train.shape[1], X_train.shape[2]))\n",
    "\n",
    "    config[\"model_type\"] = \"rnn\"\n",
    "    config[\"window_size\"] = 150\n",
    "\n",
    "    config[\"learning_rate\"] = learning_rate\n",
    "    config[\"batch_size\"] = batch_size\n",
    "    config[\"optimizer\"] = optimizer\n",
    "\n",
    "    # init wandb\n",
    "    wandb.init(entity=\"protechted\", project=f\"fall-detection\", group=f\"optuna_umafall_{config['window_size']}_{TIME}\", reinit=True, config=config)\n",
    "\n",
    "    if optimizer == \"adam\":\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == \"sgd\":\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == \"rmsprop\":\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[Precision(name=\"precision\"), Recall(name=\"recall\"), F1Score(name=\"f1\", num_classes=1, threshold=0.5)])\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor=\"val_f1\", patience=25, restore_best_weights=True, verbose=0, mode='max')\n",
    "\n",
    "    try:\n",
    "        model.fit(X_train,\n",
    "                y_train,\n",
    "                batch_size=batch_size, epochs=20,\n",
    "                validation_data=(X_val, y_val),\n",
    "                callbacks=[early_stopping, WandbCallback(monitor=\"val_f1\", mode=\"max\", labels=[\"no fall\", \"fall\"])])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        wandb.finish()\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "    pred_labels = rint(preds)\n",
    "    f1 = f1_score(y_test, pred_labels)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if nan in X_train\n",
    "from numpy import isnan\n",
    "if isnan(X_train).any():\n",
    "    print(\"nan in X_train\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"fall-detection-rnn\",\n",
    ")\n",
    "study.optimize(objective, n_trials=20, timeout=28800)#, n_jobs=1)\n",
    "\n",
    "wandb.log(\n",
    "            {\n",
    "                \"optuna_optimization_history\": optuna.visualization.plot_optimization_history(\n",
    "                    study\n",
    "                ),\n",
    "                \"optuna_param_importances\": optuna.visualization.plot_param_importances(\n",
    "                    study\n",
    "                ),\n",
    "                \"optuna_parallel_coordinate\": optuna.visualization.plot_parallel_coordinate(\n",
    "                    study\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config from wandb by run name:\n",
    "# activation\n",
    "# \"tanh\"\n",
    "# batch_size\n",
    "# 64\n",
    "# bidirectional\n",
    "# true\n",
    "# dropout\n",
    "# 0.1\n",
    "# gaussian_noise\n",
    "# 0.16112220329548682\n",
    "# learning_rate\n",
    "# 0.026837350860689297\n",
    "# model_type\n",
    "# \"rnn\"\n",
    "# n_units\n",
    "# 16\n",
    "# optimizer\n",
    "# \"sgd\"\n",
    "# recurrent_dropout\n",
    "# 0.4\n",
    "# rnn_variant\n",
    "# \"lstm\"\n",
    "# window_size\n",
    "# 150\n",
    "\n",
    "config = {\n",
    "    \"activation\": \"relu\",\n",
    "    \"batch_size\": 64,\n",
    "    \"bidirectional\": True,\n",
    "    \"dropout\": 0.3,\n",
    "    \"gaussian_noise\": 0.1,\n",
    "    \"learning_rate\": 0.04,\n",
    "    \"model_type\": \"rnn\",\n",
    "    \"n_units\": 64,\n",
    "    \"optimizer\": \"rmsprop\",\n",
    "    \"recurrent_dropout\": 0.4,\n",
    "    \"rnn_variant\": \"lstm\",\n",
    "    \"window_size\": 150\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "random_int = randint(0, 100)\n",
    "set_seed(random_int)\n",
    "print(f\"Random seed: {random_int}\")\n",
    "\n",
    "def get_model(config, input_shape: tuple):\n",
    "\n",
    "    dropout = config[\"dropout\"]\n",
    "    #recurrent_dropout = config[\"recurrent_dropout\"]\n",
    "    gaussian_noise = config[\"gaussian_noise\"]\n",
    "    #bidirectional = config[\"bidirectional\"]\n",
    "    rnn_variant = config[\"rnn_variant\"]\n",
    "    units = config[\"n_units\"]\n",
    "    activation = config[\"activation\"]\n",
    "\n",
    "    input = Input(shape=input_shape)\n",
    "    o = GaussianNoise(gaussian_noise)(input)\n",
    "\n",
    "    if rnn_variant == \"gru\":\n",
    "        #if bidirectional:\n",
    "        #    gru = GRU(units, return_sequences=False, activation=activation, recurrent_dropout=recurrent_dropout, dropout=dropout)\n",
    "        #    o = Bidirectional(gru)(o)\n",
    "        #else:\n",
    "        o = GRU(units, return_sequences=True)(o)\n",
    "        o = GRU(units, return_sequences=False)(o)\n",
    "\n",
    "    elif rnn_variant == \"lstm\":\n",
    "        #if bidirectional:\n",
    "        #    lstm = LSTM(units, return_sequences=False, activation=activation, recurrent_dropout=recurrent_dropout, dropout=dropout)\n",
    "        #    o = Bidirectional(lstm)(o)\n",
    "        #else:\n",
    "        o = LSTM(units, return_sequences=True)(o)\n",
    "        o = LSTM(units, return_sequences=False)(o)\n",
    "\n",
    "    o = Dense(units, activation=activation)(o)\n",
    "    o = Dropout(dropout)(o)\n",
    "    o = Dense(1, activation=\"sigmoid\")(o)\n",
    "\n",
    "    model = Model(inputs=input, outputs=o)\n",
    "    return model, config\n",
    "\n",
    "\n",
    "\n",
    "learning_rate = config[\"learning_rate\"]\n",
    "batch_size = config[\"batch_size\"]\n",
    "optimizer = config[\"optimizer\"]\n",
    "\n",
    "model, config = get_model(config, (X_train.shape[1], X_train.shape[2]))\n",
    "\n",
    "# init wandb\n",
    "config[\"seed\"] = random_int\n",
    "wandb.init(entity=\"protechted\", project=f\"fall-detection\", group=f\"optuna_{TIME}\", reinit=True, config=config)\n",
    "\n",
    "if optimizer == \"adam\":\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "elif optimizer == \"sgd\":\n",
    "    optimizer = SGD(learning_rate=learning_rate)\n",
    "elif optimizer == \"rmsprop\":\n",
    "    optimizer = RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "                loss=\"binary_crossentropy\",\n",
    "                metrics=[Precision(name=\"precision\"), Recall(name=\"recall\"), F1Score(name=\"f1\", num_classes=1, threshold=0.5)])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_f1\", patience=50, restore_best_weights=True, verbose=0, mode='max')\n",
    "model.fit(X_train,\n",
    "            y_train,\n",
    "            batch_size=batch_size, epochs=200,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[early_stopping, WandbCallback(monitor=\"val_f1\", mode=\"max\", labels=[\"no fall\", \"fall\"])])\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "pred_labels = rint(preds)\n",
    "\n",
    "# get confusion matrix\n",
    "#plt.rcParams['figure.figsize'] = (10, 10)\n",
    "\n",
    "# plot confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, pred_labels, labels=[0, 1])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=[0, 1])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ai-model-training-ZBO0jvbE-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6e966a0e859d66d54bfa12dbe859418671949296028374713b05f8ccbeb8962"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
