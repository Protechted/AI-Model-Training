{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fall Detection RNN Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "from utils import load_data\n",
    "\n",
    "# random seed\n",
    "from random import randint\n",
    "\n",
    "# Tensorflow and Keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GRU, LSTM, Dropout, GaussianNoise, Input, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.metrics import Recall, Precision\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "# Optimization (Optuna)\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "# metrics / evaluation\n",
    "from sklearn.metrics import f1_score\n",
    "from numpy import rint\n",
    "\n",
    "# logging\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "# datetime\n",
    "import datetime\n",
    "\n",
    "# timestamp for wandb\n",
    "TIME = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples fetched\n",
      "Data fetched\n",
      "all_samples shape: (194, 200, 7)\n",
      "all_labels shape: (194,)\n",
      "X_train shape: (135, 200, 7)\n",
      "X_val shape: (30, 200, 7)\n",
      "X_test shape: (29, 200, 7)\n",
      "X_train shape: (135, 200, 7), 1/0 ratio: 0.4\n",
      "X_val shape: (30, 200, 7), 1/0 ratio: 0.4\n",
      "X_test shape: (29, 200, 7), 1/0 ratio: 0.41379310344827586\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = load_data(win_size =200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(trial, input_shape: tuple):\n",
    "\n",
    "    dropout = trial.suggest_categorical(\"dropout\", [0.0, 0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "    #recurrent_dropout = trial.suggest_categorical(\"recurrent_dropout\", [0.0, 0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "    gaussian_noise = trial.suggest_float(\"gaussian_noise\", 0.0, 0.2)\n",
    "    #bidirectional = trial.suggest_categorical(\"bidirectional\", [True, False])\n",
    "    rnn_variant = trial.suggest_categorical(\"rnn_variant\", [\"gru\", \"lstm\"])\n",
    "    units = trial.suggest_categorical(\"n_units\", [16, 32, 64, 128])\n",
    "    activation = trial.suggest_categorical(\"activation\", [\"relu\", \"tanh\", \"leaky_relu\"])\n",
    "\n",
    "    config = {\n",
    "        \"dropout\": dropout,\n",
    "        #\"recurrent_dropout\": recurrent_dropout,\n",
    "        \"gaussian_noise\": gaussian_noise,\n",
    "        #\"bidirectional\": bidirectional,\n",
    "        \"rnn_variant\": rnn_variant,\n",
    "        \"n_units\": units,\n",
    "        \"activation\": activation,\n",
    "    }\n",
    "\n",
    "    input = Input(shape=input_shape)\n",
    "    o = GaussianNoise(gaussian_noise)(input)\n",
    "\n",
    "    if rnn_variant == \"gru\":\n",
    "        #if bidirectional:\n",
    "        #    gru = GRU(units, return_sequences=False, activation=activation, recurrent_dropout=recurrent_dropout, dropout=dropout)\n",
    "        #    o = Bidirectional(gru)(o)\n",
    "        #else:\n",
    "        o = GRU(units, return_sequences=True)(o)\n",
    "        o = GRU(units, return_sequences=False)(o)\n",
    "\n",
    "    elif rnn_variant == \"lstm\":\n",
    "        #if bidirectional:\n",
    "        #    lstm = LSTM(units, return_sequences=False, activation=activation, recurrent_dropout=recurrent_dropout, dropout=dropout)\n",
    "        #    o = Bidirectional(lstm)(o)\n",
    "        #else:\n",
    "        o = LSTM(units, return_sequences=True)(o)\n",
    "        o = LSTM(units, return_sequences=False)(o)\n",
    "\n",
    "    o = Dense(units, activation=activation)(o)\n",
    "    o = Dropout(dropout)(o)\n",
    "    o = Dense(1, activation=\"sigmoid\")(o)\n",
    "\n",
    "    model = Model(inputs=input, outputs=o)\n",
    "    return model, config\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.001, 0.05)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128, 256])\n",
    "    optimizer = trial.suggest_categorical(\"optimizer\", [\"adam\", \"sgd\", \"rmsprop\"])\n",
    "\n",
    "    model, config = get_model(trial, (X_train.shape[1], X_train.shape[2]))\n",
    "\n",
    "    config[\"model_type\"] = \"rnn\"\n",
    "    config[\"window_size\"] = 200\n",
    "\n",
    "    config[\"learning_rate\"] = learning_rate\n",
    "    config[\"batch_size\"] = batch_size\n",
    "    config[\"optimizer\"] = optimizer\n",
    "\n",
    "    # init wandb\n",
    "    wandb.init(entity=\"protechted\", project=f\"fall-detection\", group=f\"optuna_umafall_{config['window_size']}_{TIME}\", reinit=True, config=config)\n",
    "\n",
    "    if optimizer == \"adam\":\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == \"sgd\":\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == \"rmsprop\":\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[Precision(name=\"precision\"), Recall(name=\"recall\"), F1Score(name=\"f1\", num_classes=1, threshold=0.5)])\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor=\"val_f1\", patience=25, restore_best_weights=True, verbose=0, mode='max')\n",
    "\n",
    "    try:\n",
    "        model.fit(X_train,\n",
    "                y_train,\n",
    "                batch_size=batch_size, epochs=20,\n",
    "                validation_data=(X_val, y_val),\n",
    "                callbacks=[early_stopping, WandbCallback(monitor=\"val_f1\", mode=\"max\", labels=[\"no fall\", \"fall\"])])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        wandb.finish()\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "    pred_labels = rint(preds)\n",
    "    f1 = f1_score(y_test, pred_labels)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.18"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/benschaper/Documents/protechted/AI-Model-Training/training/wandb/run-20220620_180727-hhnzmyzc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/protechted/fall-detection/runs/hhnzmyzc\" target=\"_blank\">proud-lion-84</a></strong> to <a href=\"https://wandb.ai/protechted/fall-detection\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 200, 7)]          0         \n",
      "                                                                 \n",
      " gaussian_noise_11 (Gaussian  (None, 200, 7)           0         \n",
      " Noise)                                                          \n",
      "                                                                 \n",
      " bidirectional_6 (Bidirectio  (None, 256)              139264    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 172,289\n",
      "Trainable params: 172,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 5s 645ms/step - loss: 18.7058 - precision: 0.2500 - recall: 0.1471 - f1: 0.1852 - val_loss: 0.5940 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: 0.0000e+00 - _timestamp: 1655741254.0000 - _runtime: 7.0000\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 2s 383ms/step - loss: 17.2985 - precision: 0.0000e+00 - recall: 0.0000e+00 - f1: 0.0000e+00 - val_loss: 0.6757 - val_precision: 0.2727 - val_recall: 0.4286 - val_f1: 0.3333 - _timestamp: 1655741256.0000 - _runtime: 9.0000\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 1s 350ms/step - loss: 16.8913 - precision: 0.5000 - recall: 0.2353 - f1: 0.3200 - val_loss: 0.5896 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: 0.0000e+00 - _timestamp: 1655741257.0000 - _runtime: 10.0000\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 1s 228ms/step - loss: 19.1756 - precision: 0.3636 - recall: 0.2353 - f1: 0.2857 - val_loss: 0.5884 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: 0.0000e+00 - _timestamp: 1655741258.0000 - _runtime: 11.0000\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 1s 222ms/step - loss: 17.0331 - precision: 1.0000 - recall: 0.0294 - f1: 0.0571 - val_loss: 0.5950 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: 0.0000e+00 - _timestamp: 1655741259.0000 - _runtime: 12.0000\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 1s 297ms/step - loss: 16.3126 - precision: 0.5000 - recall: 0.3824 - f1: 0.4333 - val_loss: 0.6004 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: 0.0000e+00 - _timestamp: 1655741260.0000 - _runtime: 13.0000\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 1s 359ms/step - loss: 17.2979 - precision: 0.3600 - recall: 0.2647 - f1: 0.3051 - val_loss: 0.5739 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: 0.0000e+00 - _timestamp: 1655741262.0000 - _runtime: 15.0000\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 1s 332ms/step - loss: 15.7973 - precision: 0.5417 - recall: 0.3824 - f1: 0.4483 - val_loss: 0.6087 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: 0.0000e+00 - _timestamp: 1655741263.0000 - _runtime: 16.0000\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 1s 291ms/step - loss: 18.6819 - precision: 0.5909 - recall: 0.3824 - f1: 0.4643 - val_loss: 0.6235 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_f1: 0.0000e+00 - _timestamp: 1655741264.0000 - _runtime: 17.0000\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 1s 273ms/step - loss: 15.6107 - precision: 0.6875 - recall: 0.3235 - f1: 0.4400 - val_loss: 719867724126364347513773752320.0000 - val_precision: 0.3043 - val_recall: 1.0000 - val_f1: 0.4667 - _timestamp: 1655741265.0000 - _runtime: 18.0000\n",
      "Epoch 11/100\n",
      "1/4 [======>.......................] - ETA: 0s - loss: 12689778798855843028676131160064.0000 - precision: 0.2222 - recall: 0.7500 - f1: 0.3429Graph execution error:\n",
      "\n",
      "Detected at node 'assert_greater_equal/Assert/AssertGuard/Assert' defined at (most recent call last):\n",
      "    File \"/Users/benschaper/.pyenv/versions/3.8.12/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "      return _run_code(code, main_globals, None,\n",
      "    File \"/Users/benschaper/.pyenv/versions/3.8.12/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "      exec(code, run_globals)\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "      app.launch_new_instance()\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/traitlets/config/application.py\", line 976, in launch_instance\n",
      "      app.start()\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n",
      "      self.io_loop.start()\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "      self.asyncio_loop.run_forever()\n",
      "    File \"/Users/benschaper/.pyenv/versions/3.8.12/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "      self._run_once()\n",
      "    File \"/Users/benschaper/.pyenv/versions/3.8.12/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "      handle._run()\n",
      "    File \"/Users/benschaper/.pyenv/versions/3.8.12/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "      self._context.run(self._callback, *self._args)\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 508, in dispatch_queue\n",
      "      await self.process_one()\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 497, in process_one\n",
      "      await dispatch(*args)\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 404, in dispatch_shell\n",
      "      await result\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 728, in execute_request\n",
      "      reply_content = await reply_content\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
      "      res = shell.run_cell(\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
      "      return super().run_cell(*args, **kwargs)\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_cell\n",
      "      result = self._run_cell(\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2936, in _run_cell\n",
      "      return runner(coro)\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "      coro.send(None)\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3135, in run_cell_async\n",
      "      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3338, in run_ast_nodes\n",
      "      if await self.run_code(code, result, async_=asy):\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3398, in run_code\n",
      "      exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "    File \"/var/folders/c8/dsddf97j70d1c944dscbxqqw0000gn/T/ipykernel_78086/289731.py\", line 5, in <cell line: 5>\n",
      "      study.optimize(objective, n_trials=10, timeout=600)#, n_jobs=1)\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/optuna/study/study.py\", line 400, in optimize\n",
      "      _optimize(\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 66, in _optimize\n",
      "      _optimize_sequential(\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 163, in _optimize_sequential\n",
      "      trial = _run_trial(study, func, catch)\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
      "      value_or_values = func(trial)\n",
      "    File \"/var/folders/c8/dsddf97j70d1c944dscbxqqw0000gn/T/ipykernel_78086/1403804534.py\", line 85, in objective\n",
      "      model.fit(X_train,\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/wandb/integration/keras/keras.py\", line 163, in new_v2\n",
      "      return old_v2(*args, **kwargs)\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
      "      return fn(*args, **kwargs)\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1409, in fit\n",
      "      tmp_logs = self.train_function(iterator)\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1051, in train_function\n",
      "      return step_function(self, iterator)\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1040, in step_function\n",
      "      outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1030, in run_step\n",
      "      outputs = model.train_step(data)\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 894, in train_step\n",
      "      return self.compute_metrics(x, y, y_pred, sample_weight)\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 987, in compute_metrics\n",
      "      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 501, in update_state\n",
      "      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/keras/utils/metrics_utils.py\", line 70, in decorated\n",
      "      update_op = update_state_fn(*args, **kwargs)\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/keras/metrics/base_metric.py\", line 140, in update_state_fn\n",
      "      return ag_update_state(*args, **kwargs)\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/keras/metrics/metrics.py\", line 818, in update_state\n",
      "      return metrics_utils.update_confusion_matrix_variables(\n",
      "    File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/keras/utils/metrics_utils.py\", line 602, in update_confusion_matrix_variables\n",
      "      tf.debugging.assert_greater_equal(\n",
      "Node: 'assert_greater_equal/Assert/AssertGuard/Assert'\n",
      "assertion failed: [predictions must be >= 0] [Condition x >= y did not hold element-wise:] [x (model_11/dense_23/Sigmoid:0) = ] [[-nan][-nan][-nan]...] [y (Cast_2/x:0) = ] [0]\n",
      "\t [[{{node assert_greater_equal/Assert/AssertGuard/Assert}}]] [Op:__inference_train_function_101160]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f43bfe801f4fe1bc4e7b64661766e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.690 MB of 0.690 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>f1</td><td>▄▁▆▅▂█▆███</td></tr><tr><td>loss</td><td>▇▄▄█▄▂▄▁▇▁</td></tr><tr><td>precision</td><td>▃▁▅▄█▅▄▅▅▆</td></tr><tr><td>recall</td><td>▄▁▅▅▂█▆██▇</td></tr><tr><td>val_f1</td><td>▁▆▁▁▁▁▁▁▁█</td></tr><tr><td>val_loss</td><td>▁▁▁▁▁▁▁▁▁█</td></tr><tr><td>val_precision</td><td>▁▇▁▁▁▁▁▁▁█</td></tr><tr><td>val_recall</td><td>▁▄▁▁▁▁▁▁▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>9</td></tr><tr><td>best_val_f1</td><td>0.46667</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>f1</td><td>0.44</td></tr><tr><td>loss</td><td>15.61071</td></tr><tr><td>precision</td><td>0.6875</td></tr><tr><td>recall</td><td>0.32353</td></tr><tr><td>val_f1</td><td>0.46667</td></tr><tr><td>val_loss</td><td>7.198677241263643e+29</td></tr><tr><td>val_precision</td><td>0.30435</td></tr><tr><td>val_recall</td><td>1.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">proud-lion-84</strong>: <a href=\"https://wandb.ai/protechted/fall-detection/runs/hhnzmyzc\" target=\"_blank\">https://wandb.ai/protechted/fall-detection/runs/hhnzmyzc</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220620_180727-hhnzmyzc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 436ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2022-06-20 18:07:51,502]\u001b[0m Trial 0 failed because of the following error: ValueError('Input y_pred contains NaN.')\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 213, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/var/folders/c8/dsddf97j70d1c944dscbxqqw0000gn/T/ipykernel_78086/1403804534.py\", line 97, in objective\n",
      "    f1 = f1_score(y_test, pred_labels)\n",
      "  File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1132, in f1_score\n",
      "    return fbeta_score(\n",
      "  File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1270, in fbeta_score\n",
      "    _, _, f, _ = precision_recall_fscore_support(\n",
      "  File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1556, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1357, in _check_set_wise_labels\n",
      "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
      "  File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 86, in _check_targets\n",
      "    type_pred = type_of_target(y_pred, input_name=\"y_pred\")\n",
      "  File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/sklearn/utils/multiclass.py\", line 332, in type_of_target\n",
      "    _assert_all_finite(y, input_name=input_name)\n",
      "  File \"/Users/benschaper/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 146, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input y_pred contains NaN.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input y_pred contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/benschaper/Documents/protechted/AI-Model-Training/training/model_rnn_200.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benschaper/Documents/protechted/AI-Model-Training/training/model_rnn_200.ipynb#ch0000008?line=0'>1</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benschaper/Documents/protechted/AI-Model-Training/training/model_rnn_200.ipynb#ch0000008?line=1'>2</a>\u001b[0m     direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benschaper/Documents/protechted/AI-Model-Training/training/model_rnn_200.ipynb#ch0000008?line=2'>3</a>\u001b[0m     study_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfall-detection-rnn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benschaper/Documents/protechted/AI-Model-Training/training/model_rnn_200.ipynb#ch0000008?line=3'>4</a>\u001b[0m )\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/benschaper/Documents/protechted/AI-Model-Training/training/model_rnn_200.ipynb#ch0000008?line=4'>5</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, timeout\u001b[39m=\u001b[39;49m\u001b[39m600\u001b[39;49m)\u001b[39m#, n_jobs=1)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benschaper/Documents/protechted/AI-Model-Training/training/model_rnn_200.ipynb#ch0000008?line=6'>7</a>\u001b[0m wandb\u001b[39m.\u001b[39mlog(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benschaper/Documents/protechted/AI-Model-Training/training/model_rnn_200.ipynb#ch0000008?line=7'>8</a>\u001b[0m             {\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benschaper/Documents/protechted/AI-Model-Training/training/model_rnn_200.ipynb#ch0000008?line=8'>9</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39moptuna_optimization_history\u001b[39m\u001b[39m\"\u001b[39m: optuna\u001b[39m.\u001b[39mvisualization\u001b[39m.\u001b[39mplot_optimization_history(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benschaper/Documents/protechted/AI-Model-Training/training/model_rnn_200.ipynb#ch0000008?line=17'>18</a>\u001b[0m             }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benschaper/Documents/protechted/AI-Model-Training/training/model_rnn_200.ipynb#ch0000008?line=18'>19</a>\u001b[0m         )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benschaper/Documents/protechted/AI-Model-Training/training/model_rnn_200.ipynb#ch0000008?line=20'>21</a>\u001b[0m wandb\u001b[39m.\u001b[39mfinish()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/optuna/study/study.py:400\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[39mif\u001b[39;00m n_jobs \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    393\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    394\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`n_jobs` argument has been deprecated in v2.7.0. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    395\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis feature will be removed in v4.0.0. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    396\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSee https://github.com/optuna/optuna/releases/tag/v2.7.0.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    397\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    398\u001b[0m     )\n\u001b[0;32m--> 400\u001b[0m _optimize(\n\u001b[1;32m    401\u001b[0m     study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    402\u001b[0m     func\u001b[39m=\u001b[39;49mfunc,\n\u001b[1;32m    403\u001b[0m     n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[1;32m    404\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    405\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    406\u001b[0m     catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[1;32m    407\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    408\u001b[0m     gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[1;32m    409\u001b[0m     show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[1;32m    410\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[1;32m     67\u001b[0m             study,\n\u001b[1;32m     68\u001b[0m             func,\n\u001b[1;32m     69\u001b[0m             n_trials,\n\u001b[1;32m     70\u001b[0m             timeout,\n\u001b[1;32m     71\u001b[0m             catch,\n\u001b[1;32m     72\u001b[0m             callbacks,\n\u001b[1;32m     73\u001b[0m             gc_after_trial,\n\u001b[1;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m show_progress_bar:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    164\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/optuna/study/_optimize.py:264\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    263\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch):\n\u001b[0;32m--> 264\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[1;32m    265\u001b[0m \u001b[39mreturn\u001b[39;00m trial\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/optuna/study/_optimize.py:213\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    210\u001b[0m     thread\u001b[39m.\u001b[39mstart()\n\u001b[1;32m    212\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 213\u001b[0m     value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[1;32m    214\u001b[0m \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32m/Users/benschaper/Documents/protechted/AI-Model-Training/training/model_rnn_200.ipynb Cell 8'\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benschaper/Documents/protechted/AI-Model-Training/training/model_rnn_200.ipynb#ch0000007?line=94'>95</a>\u001b[0m preds \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benschaper/Documents/protechted/AI-Model-Training/training/model_rnn_200.ipynb#ch0000007?line=95'>96</a>\u001b[0m pred_labels \u001b[39m=\u001b[39m rint(preds)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/benschaper/Documents/protechted/AI-Model-Training/training/model_rnn_200.ipynb#ch0000007?line=96'>97</a>\u001b[0m f1 \u001b[39m=\u001b[39m f1_score(y_test, pred_labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benschaper/Documents/protechted/AI-Model-Training/training/model_rnn_200.ipynb#ch0000007?line=97'>98</a>\u001b[0m \u001b[39mreturn\u001b[39;00m f1\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1132\u001b[0m, in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m    997\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf1_score\u001b[39m(\n\u001b[1;32m    998\u001b[0m     y_true,\n\u001b[1;32m    999\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1006\u001b[0m ):\n\u001b[1;32m   1007\u001b[0m     \u001b[39m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m \n\u001b[1;32m   1009\u001b[0m \u001b[39m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[39m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1132\u001b[0m     \u001b[39mreturn\u001b[39;00m fbeta_score(\n\u001b[1;32m   1133\u001b[0m         y_true,\n\u001b[1;32m   1134\u001b[0m         y_pred,\n\u001b[1;32m   1135\u001b[0m         beta\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m   1136\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   1137\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[1;32m   1138\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m   1139\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1140\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m   1141\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1270\u001b[0m, in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfbeta_score\u001b[39m(\n\u001b[1;32m   1145\u001b[0m     y_true,\n\u001b[1;32m   1146\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1154\u001b[0m ):\n\u001b[1;32m   1155\u001b[0m     \u001b[39m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m \n\u001b[1;32m   1157\u001b[0m \u001b[39m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1267\u001b[0m \u001b[39m    array([0.71..., 0.        , 0.        ])\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1270\u001b[0m     _, _, f, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[1;32m   1271\u001b[0m         y_true,\n\u001b[1;32m   1272\u001b[0m         y_pred,\n\u001b[1;32m   1273\u001b[0m         beta\u001b[39m=\u001b[39;49mbeta,\n\u001b[1;32m   1274\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   1275\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[1;32m   1276\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m   1277\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mf-score\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[1;32m   1278\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1279\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m   1280\u001b[0m     )\n\u001b[1;32m   1281\u001b[0m     \u001b[39mreturn\u001b[39;00m f\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1556\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1554\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1555\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1556\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[1;32m   1558\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1357\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1354\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m average_options \u001b[39mand\u001b[39;00m average \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1355\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39maverage has to be one of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(average_options))\n\u001b[0;32m-> 1357\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m   1358\u001b[0m \u001b[39m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   1359\u001b[0m \u001b[39m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   1360\u001b[0m present_labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/sklearn/metrics/_classification.py:86\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     84\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m     85\u001b[0m type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 86\u001b[0m type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39my_pred\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     88\u001b[0m y_type \u001b[39m=\u001b[39m {type_true, type_pred}\n\u001b[1;32m     89\u001b[0m \u001b[39mif\u001b[39;00m y_type \u001b[39m==\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/sklearn/utils/multiclass.py:332\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39m# check float and contains non-integer float values\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[39mif\u001b[39;00m y\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39many(y \u001b[39m!=\u001b[39m y\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)):\n\u001b[1;32m    331\u001b[0m     \u001b[39m# [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]\u001b[39;00m\n\u001b[0;32m--> 332\u001b[0m     _assert_all_finite(y, input_name\u001b[39m=\u001b[39;49minput_name)\n\u001b[1;32m    333\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcontinuous\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m suffix\n\u001b[1;32m    335\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39munique(y)) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m) \u001b[39mor\u001b[39;00m (y\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(y[\u001b[39m0\u001b[39m]) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/ai-model-training-ZBO0jvbE-py3.8/lib/python3.8/site-packages/sklearn/utils/validation.py:146\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    125\u001b[0m             \u001b[39mnot\u001b[39;00m allow_nan\n\u001b[1;32m    126\u001b[0m             \u001b[39mand\u001b[39;00m estimator_name\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    131\u001b[0m             \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m             msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[1;32m    133\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    144\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m             )\n\u001b[0;32m--> 146\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n\u001b[1;32m    148\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input y_pred contains NaN."
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"fall-detection-rnn\",\n",
    ")\n",
    "study.optimize(objective, n_trials=20, timeout=600)#, n_jobs=1)\n",
    "\n",
    "wandb.log(\n",
    "            {\n",
    "                \"optuna_optimization_history\": optuna.visualization.plot_optimization_history(\n",
    "                    study\n",
    "                ),\n",
    "                \"optuna_param_importances\": optuna.visualization.plot_param_importances(\n",
    "                    study\n",
    "                ),\n",
    "                \"optuna_parallel_coordinate\": optuna.visualization.plot_parallel_coordinate(\n",
    "                    study\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config from wandb by run name:\n",
    "# activation\n",
    "# \"tanh\"\n",
    "# batch_size\n",
    "# 64\n",
    "# bidirectional\n",
    "# true\n",
    "# dropout\n",
    "# 0.1\n",
    "# gaussian_noise\n",
    "# 0.16112220329548682\n",
    "# learning_rate\n",
    "# 0.026837350860689297\n",
    "# model_type\n",
    "# \"rnn\"\n",
    "# n_units\n",
    "# 16\n",
    "# optimizer\n",
    "# \"sgd\"\n",
    "# recurrent_dropout\n",
    "# 0.4\n",
    "# rnn_variant\n",
    "# \"lstm\"\n",
    "# window_size\n",
    "# 150\n",
    "\n",
    "config = {\n",
    "    \"activation\": \"tanh\",\n",
    "    \"batch_size\": 64,\n",
    "    \"bidirectional\": True,\n",
    "    \"dropout\": 0.1,\n",
    "    \"gaussian_noise\": 0.16112220329548682,\n",
    "    \"learning_rate\": 0.026837350860689297,\n",
    "    \"model_type\": \"rnn\",\n",
    "    \"n_units\": 16,\n",
    "    \"optimizer\": \"sgd\",\n",
    "    \"recurrent_dropout\": 0.4,\n",
    "    \"rnn_variant\": \"lstm\",\n",
    "    \"window_size\": 150\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed: 92\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.18"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/benschaper/Documents/protechted/AI-Model-Training/training/wandb/run-20220620_171517-1czcr0ch</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/protechted/fall-detection/runs/1czcr0ch\" target=\"_blank\">firm-dawn-72</a></strong> to <a href=\"https://wandb.ai/protechted/fall-detection\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_56 (InputLayer)       [(None, 150, 7)]          0         \n",
      "                                                                 \n",
      " gaussian_noise_55 (Gaussian  (None, 150, 7)           0         \n",
      " Noise)                                                          \n",
      "                                                                 \n",
      " bidirectional_34 (Bidirecti  (None, 150, 32)          3072      \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_35 (Bidirecti  (None, 32)               6272      \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,889\n",
      "Trainable params: 9,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 13s 333ms/step - loss: 0.6815 - precision: 0.5699 - recall: 0.8893 - f1: 0.6946 - val_loss: 0.7230 - val_precision: 0.4891 - val_recall: 0.9278 - val_f1: 0.6406 - _timestamp: 1655738132.0000 - _runtime: 15.0000\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 5s 277ms/step - loss: 0.6780 - precision: 0.5705 - recall: 0.8959 - f1: 0.6971 - val_loss: 0.7264 - val_precision: 0.5026 - val_recall: 1.0000 - val_f1: 0.6690 - _timestamp: 1655738137.0000 - _runtime: 20.0000\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 6s 341ms/step - loss: 0.6780 - precision: 0.5693 - recall: 0.8959 - f1: 0.6962 - val_loss: 0.7248 - val_precision: 0.5000 - val_recall: 1.0000 - val_f1: 0.6667 - _timestamp: 1655738144.0000 - _runtime: 27.0000\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 7s 411ms/step - loss: 0.6761 - precision: 0.5716 - recall: 0.9041 - f1: 0.7004 - val_loss: 0.7196 - val_precision: 0.4918 - val_recall: 0.9278 - val_f1: 0.6429 - _timestamp: 1655738151.0000 - _runtime: 34.0000\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 9s 478ms/step - loss: 0.6732 - precision: 0.5792 - recall: 0.8760 - f1: 0.6974 - val_loss: 0.7192 - val_precision: 0.4973 - val_recall: 0.9588 - val_f1: 0.6549 - _timestamp: 1655738159.0000 - _runtime: 42.0000\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 10s 583ms/step - loss: 0.6710 - precision: 0.5855 - recall: 0.8942 - f1: 0.7077 - val_loss: 0.7247 - val_precision: 0.5000 - val_recall: 1.0000 - val_f1: 0.6667 - _timestamp: 1655738170.0000 - _runtime: 53.0000\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 13s 736ms/step - loss: 0.6695 - precision: 0.5793 - recall: 0.8992 - f1: 0.7047 - val_loss: 0.7229 - val_precision: 0.5026 - val_recall: 1.0000 - val_f1: 0.6690 - _timestamp: 1655738183.0000 - _runtime: 66.0000\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 16s 910ms/step - loss: 0.6695 - precision: 0.5816 - recall: 0.8893 - f1: 0.7033 - val_loss: 0.7208 - val_precision: 0.5105 - val_recall: 1.0000 - val_f1: 0.6760 - _timestamp: 1655738199.0000 - _runtime: 82.0000\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.6669 - precision: 0.5880 - recall: 0.8893 - f1: 0.7079 - val_loss: 0.7140 - val_precision: 0.5000 - val_recall: 0.9175 - val_f1: 0.6473 - _timestamp: 1655738218.0000 - _runtime: 101.0000\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 19s 1s/step - loss: 0.6601 - precision: 0.6012 - recall: 0.8595 - f1: 0.7075 - val_loss: 0.7201 - val_precision: 0.5160 - val_recall: 1.0000 - val_f1: 0.6807 - _timestamp: 1655738237.0000 - _runtime: 120.0000\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 18s 983ms/step - loss: 0.6587 - precision: 0.6039 - recall: 0.8744 - f1: 0.7144 - val_loss: 0.7196 - val_precision: 0.5187 - val_recall: 1.0000 - val_f1: 0.6831 - _timestamp: 1655738254.0000 - _runtime: 137.0000\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 18s 1s/step - loss: 0.6585 - precision: 0.6000 - recall: 0.8777 - f1: 0.7128 - val_loss: 0.7071 - val_precision: 0.5497 - val_recall: 0.9691 - val_f1: 0.7015 - _timestamp: 1655738273.0000 - _runtime: 156.0000\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 17s 959ms/step - loss: 0.6553 - precision: 0.6110 - recall: 0.8463 - f1: 0.7096 - val_loss: 0.7099 - val_precision: 0.5449 - val_recall: 1.0000 - val_f1: 0.7055 - _timestamp: 1655738290.0000 - _runtime: 173.0000\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 16s 895ms/step - loss: 0.6509 - precision: 0.6157 - recall: 0.8711 - f1: 0.7214 - val_loss: 0.7114 - val_precision: 0.5419 - val_recall: 1.0000 - val_f1: 0.7029 - _timestamp: 1655738306.0000 - _runtime: 189.0000\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 15s 823ms/step - loss: 0.6490 - precision: 0.6262 - recall: 0.8777 - f1: 0.7309 - val_loss: 0.7216 - val_precision: 0.5215 - val_recall: 1.0000 - val_f1: 0.6855 - _timestamp: 1655738321.0000 - _runtime: 204.0000\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 14s 766ms/step - loss: 0.6500 - precision: 0.6162 - recall: 0.8942 - f1: 0.7296 - val_loss: 0.7006 - val_precision: 0.5543 - val_recall: 1.0000 - val_f1: 0.7132 - _timestamp: 1655738334.0000 - _runtime: 217.0000\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 14s 762ms/step - loss: 0.6411 - precision: 0.6305 - recall: 0.8463 - f1: 0.7227 - val_loss: 0.7006 - val_precision: 0.5543 - val_recall: 1.0000 - val_f1: 0.7132 - _timestamp: 1655738348.0000 - _runtime: 231.0000\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 13s 736ms/step - loss: 0.6382 - precision: 0.6266 - recall: 0.8347 - f1: 0.7158 - val_loss: 0.6962 - val_precision: 0.5607 - val_recall: 1.0000 - val_f1: 0.7185 - _timestamp: 1655738361.0000 - _runtime: 244.0000\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 14s 753ms/step - loss: 0.6400 - precision: 0.6320 - recall: 0.8347 - f1: 0.7194 - val_loss: 0.6918 - val_precision: 0.5706 - val_recall: 1.0000 - val_f1: 0.7266 - _timestamp: 1655738375.0000 - _runtime: 258.0000\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 15s 841ms/step - loss: 0.6359 - precision: 0.6340 - recall: 0.8331 - f1: 0.7200 - val_loss: 0.6794 - val_precision: 0.5676 - val_recall: 0.8660 - val_f1: 0.6857 - _timestamp: 1655738390.0000 - _runtime: 273.0000\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 16s 882ms/step - loss: 0.6323 - precision: 0.6397 - recall: 0.7719 - f1: 0.6996 - val_loss: 0.7045 - val_precision: 0.5330 - val_recall: 1.0000 - val_f1: 0.6953 - _timestamp: 1655738406.0000 - _runtime: 289.0000\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 16s 878ms/step - loss: 0.6274 - precision: 0.6388 - recall: 0.8975 - f1: 0.7464 - val_loss: 0.6738 - val_precision: 0.5854 - val_recall: 0.9897 - val_f1: 0.7356 - _timestamp: 1655738422.0000 - _runtime: 305.0000\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 16s 893ms/step - loss: 0.6237 - precision: 0.6488 - recall: 0.8000 - f1: 0.7165 - val_loss: 0.6618 - val_precision: 0.5772 - val_recall: 0.8866 - val_f1: 0.6992 - _timestamp: 1655738438.0000 - _runtime: 321.0000\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 16s 912ms/step - loss: 0.6188 - precision: 0.6499 - recall: 0.7488 - f1: 0.6959 - val_loss: 0.6824 - val_precision: 0.5607 - val_recall: 1.0000 - val_f1: 0.7185 - _timestamp: 1655738454.0000 - _runtime: 337.0000\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 17s 960ms/step - loss: 0.6211 - precision: 0.6530 - recall: 0.8149 - f1: 0.7250 - val_loss: 0.6700 - val_precision: 0.5673 - val_recall: 1.0000 - val_f1: 0.7239 - _timestamp: 1655738471.0000 - _runtime: 354.0000\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 17s 963ms/step - loss: 0.6162 - precision: 0.6549 - recall: 0.8281 - f1: 0.7314 - val_loss: 0.6920 - val_precision: 0.5480 - val_recall: 1.0000 - val_f1: 0.7080 - _timestamp: 1655738489.0000 - _runtime: 372.0000\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 17s 943ms/step - loss: 0.6095 - precision: 0.6554 - recall: 0.8678 - f1: 0.7468 - val_loss: 0.6681 - val_precision: 0.5607 - val_recall: 1.0000 - val_f1: 0.7185 - _timestamp: 1655738506.0000 - _runtime: 389.0000\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 17s 945ms/step - loss: 0.6044 - precision: 0.6572 - recall: 0.8430 - f1: 0.7386 - val_loss: 0.6607 - val_precision: 0.5671 - val_recall: 0.9588 - val_f1: 0.7126 - _timestamp: 1655738523.0000 - _runtime: 406.0000\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 18s 980ms/step - loss: 0.5992 - precision: 0.6693 - recall: 0.8463 - f1: 0.7474 - val_loss: 0.6563 - val_precision: 0.5647 - val_recall: 0.9897 - val_f1: 0.7191 - _timestamp: 1655738540.0000 - _runtime: 423.0000\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 16s 913ms/step - loss: 0.5980 - precision: 0.6694 - recall: 0.8198 - f1: 0.7370 - val_loss: 0.6715 - val_precision: 0.5509 - val_recall: 0.9485 - val_f1: 0.6970 - _timestamp: 1655738557.0000 - _runtime: 440.0000\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 15s 862ms/step - loss: 0.5872 - precision: 0.6730 - recall: 0.8744 - f1: 0.7606 - val_loss: 0.6544 - val_precision: 0.5753 - val_recall: 0.8660 - val_f1: 0.6914 - _timestamp: 1655738572.0000 - _runtime: 455.0000\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 16s 882ms/step - loss: 0.5814 - precision: 0.6782 - recall: 0.8430 - f1: 0.7517 - val_loss: 0.7403 - val_precision: 0.5140 - val_recall: 0.9485 - val_f1: 0.6667 - _timestamp: 1655738588.0000 - _runtime: 471.0000\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 16s 876ms/step - loss: 0.5757 - precision: 0.6704 - recall: 0.8975 - f1: 0.7675 - val_loss: 0.6806 - val_precision: 0.5440 - val_recall: 0.7010 - val_f1: 0.6126 - _timestamp: 1655738604.0000 - _runtime: 487.0000\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 16s 874ms/step - loss: 0.5738 - precision: 0.6883 - recall: 0.8579 - f1: 0.7638 - val_loss: 0.7032 - val_precision: 0.5584 - val_recall: 0.8866 - val_f1: 0.6853 - _timestamp: 1655738619.0000 - _runtime: 502.0000\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 15s 856ms/step - loss: 0.5596 - precision: 0.6800 - recall: 0.8992 - f1: 0.7744 - val_loss: 0.6773 - val_precision: 0.5634 - val_recall: 0.8247 - val_f1: 0.6695 - _timestamp: 1655738635.0000 - _runtime: 518.0000\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 15s 849ms/step - loss: 0.5524 - precision: 0.6893 - recall: 0.8909 - f1: 0.7772 - val_loss: 0.7122 - val_precision: 0.5685 - val_recall: 0.8557 - val_f1: 0.6831 - _timestamp: 1655738650.0000 - _runtime: 533.0000\n",
      "Epoch 37/200\n",
      " 4/18 [=====>........................] - ETA: 12s - loss: 0.5038 - precision: 0.7219 - recall: 0.9375 - f1: 0.8157"
     ]
    }
   ],
   "source": [
    "# set seed\n",
    "random_int = randint(0, 100)\n",
    "set_seed(random_int)\n",
    "print(f\"Random seed: {random_int}\")\n",
    "\n",
    "def get_model(config, input_shape: tuple):\n",
    "\n",
    "    dropout = config[\"dropout\"]\n",
    "    recurrent_dropout = config[\"recurrent_dropout\"]\n",
    "    gaussian_noise = config[\"gaussian_noise\"]\n",
    "    bidirectional = config[\"bidirectional\"]\n",
    "    rnn_variant = config[\"rnn_variant\"]\n",
    "    units = config[\"n_units\"]\n",
    "    activation = config[\"activation\"]\n",
    "\n",
    "    input = Input(shape=input_shape)\n",
    "    o = GaussianNoise(gaussian_noise)(input)\n",
    "\n",
    "    if rnn_variant == \"gru\":\n",
    "        if bidirectional:\n",
    "            gru = GRU(units, return_sequences=False, activation=activation, recurrent_dropout=recurrent_dropout, dropout=dropout)\n",
    "            o = Bidirectional(gru)(o)\n",
    "        else:\n",
    "            o = GRU(units, dropout=dropout, recurrent_dropout=recurrent_dropout, return_sequences=False)(o)\n",
    "\n",
    "    elif rnn_variant == \"lstm\":\n",
    "        if bidirectional:\n",
    "            lstm = LSTM(units, return_sequences=True, activation=activation, recurrent_dropout=recurrent_dropout, dropout=dropout)\n",
    "            o = Bidirectional(lstm)(o)\n",
    "            lstm = LSTM(units, return_sequences=False, activation=activation, recurrent_dropout=recurrent_dropout, dropout=dropout)\n",
    "            o = Bidirectional(lstm)(o)\n",
    "        else:\n",
    "            o = LSTM(units, dropout=dropout, recurrent_dropout=recurrent_dropout, return_sequences=False)(o)\n",
    "\n",
    "    o = Dense(units, activation=activation)(o)\n",
    "    o = Dropout(dropout)(o)\n",
    "    o = Dense(1, activation=\"sigmoid\")(o)\n",
    "\n",
    "    model = Model(inputs=input, outputs=o)\n",
    "    return model, config\n",
    "\n",
    "\n",
    "\n",
    "learning_rate = config[\"learning_rate\"]\n",
    "batch_size = config[\"batch_size\"]\n",
    "optimizer = config[\"optimizer\"]\n",
    "\n",
    "model, config = get_model(config, (X_train.shape[1], X_train.shape[2]))\n",
    "\n",
    "# init wandb\n",
    "config[\"seed\"] = random_int\n",
    "wandb.init(entity=\"protechted\", project=f\"fall-detection\", group=f\"optuna_{TIME}\", reinit=True, config=config)\n",
    "\n",
    "if optimizer == \"adam\":\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "elif optimizer == \"sgd\":\n",
    "    optimizer = SGD(learning_rate=learning_rate)\n",
    "elif optimizer == \"rmsprop\":\n",
    "    optimizer = RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "                loss=\"binary_crossentropy\",\n",
    "                metrics=[Precision(name=\"precision\"), Recall(name=\"recall\"), F1Score(name=\"f1\", num_classes=1, threshold=0.5)])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_f1\", patience=50, restore_best_weights=True, verbose=0, mode='max')\n",
    "model.fit(X_train,\n",
    "            y_train,\n",
    "            batch_size=batch_size, epochs=200,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[early_stopping, WandbCallback(monitor=\"val_f1\", mode=\"max\", labels=[\"no fall\", \"fall\"])])\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ai-model-training-ZBO0jvbE-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a6e966a0e859d66d54bfa12dbe859418671949296028374713b05f8ccbeb8962"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
